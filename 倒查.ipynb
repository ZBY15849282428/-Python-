{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# this version asks the network what the image should be, given a label\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit(), and its inverse logit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"E:/提交/学习/mnist/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"E:/提交/学习/mnist/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9727\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26435895748>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 9\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
